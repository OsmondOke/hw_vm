{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "theoretical-vegetation",
   "metadata": {},
   "source": [
    "## Assignment 12\n",
    "#### By Osmond Oke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "emotional-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    " \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    " \n",
    "tensorflow.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.disable_eager_execution\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alternative-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fourth-kentucky",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 14, 14, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 64)     18496       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3136)         0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           50192       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            34          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            34          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sampling (Sampling)             (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 69,076\n",
      "Trainable params: 69,076\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "statutory-harbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 65,089\n",
      "Trainable params: 65,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "animal-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = encoder(data)\n",
    "            reconstruction = decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction)\n",
    "            )\n",
    "            reconstruction_loss *= 28 * 28\n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= -0.5\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "romance-operation",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The model cannot be compiled because it has no loss to optimize.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3c8c3aca4464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_digits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m     return func.fit(\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m                                                      steps_per_epoch, x)\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m     x, y, sample_weights = model._standardize_user_data(\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2311\u001b[0m     \u001b[0mis_compile_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2313\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2314\u001b[0m       \u001b[0mis_compile_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_compile_from_inputs\u001b[0;34m(self, all_inputs, target, orig_inputs, orig_target)\u001b[0m\n\u001b[1;32m   2561\u001b[0m         \u001b[0mtarget_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2563\u001b[0;31m     self.compile(\n\u001b[0m\u001b[1;32m   2564\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m       \u001b[0;31m# Creates the model loss and weighted metrics sub-graphs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_weights_loss_and_weighted_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0;31m# Functions for train, test and predict will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_compile_weights_loss_and_weighted_metrics\u001b[0;34m(self, sample_weights)\u001b[0m\n\u001b[1;32m   1541\u001b[0m       \u001b[0;31m#                   loss_weight_2 * output_2_loss_fn(...) +\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m       \u001b[0;31m#                   layer losses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_total_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_skip_target_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_prepare_total_loss\u001b[0;34m(self, masks)\u001b[0m\n\u001b[1;32m   1636\u001b[0m         \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mloss_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1638\u001b[0;31m         raise ValueError('The model cannot be compiled '\n\u001b[0m\u001b[1;32m   1639\u001b[0m                          'because it has no loss to optimize.')\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The model cannot be compiled because it has no loss to optimize."
     ]
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(mnist_digits, epochs=30, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "future-newcastle",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (16), usually from a call to set_ticks, does not match the number of ticklabels (15).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-400013330be1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mplot_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-400013330be1>\u001b[0m in \u001b[0;36mplot_latent\u001b[0;34m(encoder, decoder)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0msample_range_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0msample_range_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_range_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_range_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"z[0]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mxticks\u001b[0;34m(ticks, labels, **kwargs)\u001b[0m\n\u001b[1;32m   1657\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[0;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1794\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1796\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_keyword_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3.2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"minor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1715\u001b[0m             \u001b[0;31m# remove all tick labels, so only error for > 0 ticklabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1718\u001b[0m                     \u001b[0;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m                     \u001b[0;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (16), usually from a call to set_ticks, does not match the number of ticklabels (15)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_latent(encoder, decoder):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    n = 15\n",
    "    digit_size = 28\n",
    "    scale = 2.0\n",
    "    figsize = 15\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range + 1\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.savefig(\"mnist_vae.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-antibody",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
