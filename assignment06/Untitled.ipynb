{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceramic-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "import hashlib\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pygeohash\n",
    "import s3fs\n",
    "\n",
    "endpoint_url='https://storage.budsc.midwest-datascience.com'\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "results_dir = current_dir.joinpath('results')\n",
    "\n",
    "if results_dir.exists():\n",
    "    shutil.rmtree(results_dir)\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def read_jsonl_data():\n",
    "    s3 = s3fs.S3FileSystem(\n",
    "        anon=True,\n",
    "        client_kwargs={\n",
    "            'endpoint_url': endpoint_url\n",
    "        }\n",
    "    )\n",
    "    src_data_path = 'data/processed/openflights/routes.jsonl.gz'\n",
    "    with s3.open(src_data_path, 'rb') as f_gz:\n",
    "        with gzip.open(f_gz, 'rb') as f:\n",
    "            records = [json.loads(line) for line in f.readlines()]\n",
    "    return records\n",
    "\n",
    "def flatten_record(record):\n",
    "    flat_record = dict()\n",
    "    \n",
    "    for key, value in record.items():\n",
    "        if key in ['airline', 'src_airport', 'dst_airport']:\n",
    "            if isinstance(value, dict):\n",
    "                for child_key, child_value in value.items():\n",
    "                    flat_key = '{}_{}'.format(key, child_key)\n",
    "                    flat_record[flat_key] = child_value\n",
    "        else:\n",
    "            flat_record[key] = value\n",
    "    return flat_record\n",
    "\n",
    "def create_flattened_dataset():\n",
    "    records = read_jsonl_data()\n",
    "    parquet_path = results_dir.joinpath('routes-flattened.parquet')\n",
    "    return pd.DataFrame.from_records([flatten_record(record) for record in records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "martial-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_flattened_dataset()\n",
    "df['key'] = df['src_airport_iata'].astype(str) + df['dst_airport_iata'].astype(str) + df['airline_iata'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "engaged-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = (\n",
    "        ('A', 'A'), ('B', 'B'), ('C', 'D'), ('E', 'F'),\n",
    "        ('G', 'H'), ('I', 'J'), ('K', 'L'), ('M', 'M'),\n",
    "        ('N', 'N'), ('O', 'P'), ('Q', 'R'), ('S', 'T'),\n",
    "        ('U', 'U'), ('V', 'V'), ('W', 'X'), ('Y', 'Z')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "consolidated-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nan values are causing an issue with key assignment so I am removing them from the dataset.\n",
    "df = df[df['src_airport_iata'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "funded-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['kv_key'] = df['key'].str[0]\n",
    "\n",
    "#assign a value fromt he partitions list of tuples\n",
    "df['kv_key'] = df['kv_key'].apply(lambda x: [str('-'.join(partition)) for partition in partitions if (str(x) >= partition[0]) & (str(x) <= partition[1])])\n",
    "\n",
    "# the result of the previous assignment were lists so here I am converting them to strings\n",
    "df['kv_key'] = [''.join(partition) for partition in df['kv_key']] \n",
    "\n",
    "#here i'm replacing the partitions that have the same start and end letter with a single letter\n",
    "df['kv_key'] = [partition[0] if partition[0] == partition[2] else partition for partition in df['kv_key']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "charitable-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\n",
    "    path='results/kv', \n",
    "    partition_cols=['kv_key']\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-picnic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
